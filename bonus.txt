#### -- Bonus -- ####
1. -e --early, early stopping
2. -a --architecture
3. Additional metrics & confusion matrix
4. -mse (mean squared error), & -rmse (root mean squared error) loss functions
5. -l --learning, -ep --epochs & -s --seed

6. test.sh
7. No libraries for data frames or matrix multiplication
	(only math.Exp .Log & .Sqrt, stat.Mean & .Variance)
8. README.md
9. Can watch model.json learn


#### -- loss < 0.08 -- ####

go run main.go -t -p -e -s 1619696818483627000    - test loss: 0.070008
go run main.go -t -p -e -s 1619707987089926000    - test loss: 0.059896
go run main.go -t -p -e -s 1619687999274871000    - test loss: 0.059255
go run main.go -t -p -e -s 4242                   - test loss: 0.042596
go run main.go -t -p -e -s 1619699659782358000    - test loss: 0.031915
go run main.go -t -p -e -s 1619787177180511000    - test loss: 0.031636
go run main.go -t -p -e -s 1619720454332218000    - test loss: 0.024296
go run main.go -t -p -e -s 1619947830718951000    - test loss: 0.021450
go run main.go -t -p -e -s 1620059181132839000    - test loss: 0.018200


#### -- TO DO -- ####

- fix problem with 3+ layer architecture? => exploding / vanishing gradients
