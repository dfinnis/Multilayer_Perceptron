#### -- Bonus -- ####
1. -e --early, early stopping
2. -a --architecture
3. Additional metrics & confusion matrix
4. -mse (mean squared error), & -rmse (root mean squared error) loss functions
5. -l --learning, -ep --epochs & -s --seed

6. test.sh
7. No libraries for data frames or matrix multiplication
	(only math.Exp .Log & .Sqrt, stat.Mean & .Variance)
8. README.md
9. Can watch model.json learn


#### -- loss < 0.08 -- ####

Random seed: 1619696818483627000  - test loss: 0.070008
Random seed: 1619707987089926000  - test loss: 0.059896
Random seed: 1619687999274871000  - test loss: 0.059255
Random seed: 4242                 - test loss: 0.042596
Random seed: 1619699659782358000  - test loss: 0.031915
Random seed: 1619787177180511000  - test loss: 0.031636
Random seed: 1619720454332218000  - test loss: 0.024296
Random seed: 1619947830718951000  - test loss: 0.021450
Random seed: 1620059181132839000  - test loss: 0.018200


#### -- TO DO -- ####

- fix problem with 3+ layer architecture? => exploding / vanishing gradients
